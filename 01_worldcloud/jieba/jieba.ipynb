{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import jieba\n",
    "import pprint\n",
    "\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于Jieba的三种分词示例\n",
    "\n",
    "- jieba.cut 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用HMM 模型\n",
    "- jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。 \n",
    "  <br/>注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8\n",
    "- jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用 `jieba.lcut` 以及 `jieba.lcut_for_search` 直接返回 list\n",
    "- jieba.Tokenizer(dictionary=DEFAULT_DICT) 新建自定义分词器，可用于同时使用不同词典。jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.633 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全模式分词：{ 106}\n",
      "真是/好久/好久好久/好久/好久没/没来/哈/皮/娜拉/野生/野生动物/生动/动物/动物园/了///记忆/记忆里/还是/小时/小时候/时候/三四/三四年/四年/四年级/年级/学校/组织/春游/游去/的/银河/银河系/河系//jieba/cut/for/search//方法/接受/两个/参数///需要/分词/的/字符/字符串///是否/使用//HMM//模型///该/方法/适合/合用/用于/搜索/搜索引擎/索引/引擎/构建/倒排/索引/的/分词///粒度/比较/细/待/分词/的/字符/字符串/可以/以是//unicode//或//UTF/8//字符/字符串//GBK//字符/字符串//\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "import jieba,math\n",
    "import jieba.analyse\n",
    "\n",
    "#jieba.cut主要有三种模式\n",
    "#随便对一个动物园的评论进行分析\n",
    "str_text=\"真是好久好久没来哈皮娜拉野生动物园了，记忆里还是小时候三四年级学校组织春游去的银河系。jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。\"\n",
    "#全模式cut_all=True\n",
    "cut1 = jieba.cut(str_text,cut_all=True)\n",
    "print(type(cut1))\n",
    "lst_quan1 = list(cut1)\n",
    "print('全模式分词：{ %d}' % len(lst_quan1))\n",
    "print(\"/\".join(lst_quan1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精准模式分词：{ 80}\n",
      "真是/好久好久/没来/哈皮/娜拉/野生/动物园/了/，/记忆里/还是/小时候/三四年/级/学校/组织/春游/去/的/银河系/。/jieba/./cut/_/for/_/search/ /方法/接受/两个/参数/：/需要/分词/的/字符串/；/是否/使用/ /HMM/ /模型/。/该/方法/适合/用于/搜索引擎/构建/倒排/索引/的/分词/，/粒度/比较/细待/分词/的/字符串/可以/是/ /unicode/ /或/ /UTF/-/8/ /字符串/、/GBK/ /字符串/。\n"
     ]
    }
   ],
   "source": [
    "#精准模式cut_all=False，默认即是\n",
    "cut2=jieba.cut(str_text,cut_all=False)\n",
    "lst_jing2 = list(cut2)\n",
    "print('精准模式分词：{ %d}' % len(lst_jing2))\n",
    "print(\"/\".join(lst_jing2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "搜索引擎分词：{ 97}\n",
      "真是/好久/好久/好久好久/没来/哈皮/娜拉/野生/动物/动物园/了/，/记忆/记忆里/还是/小时/时候/小时候/三四/四年/三四年/级/学校/组织/春游/去/的/银河/河系/银河系/。/jieba/./cut/_/for/_/search/ /方法/接受/两个/参数/：/需要/分词/的/字符/字符串/；/是否/使用/ /HMM/ /模型/。/该/方法/适合/用于/搜索/索引/引擎/搜索引擎/构建/倒排/索引/的/分词/，/粒度/比较/细待/分词/的/字符/字符串/可以/是/ /unicode/ /或/ /UTF/-/8/ /字符/字符串/、/GBK/ /字符/字符串/。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#搜索引擎模式  cut_for_search\n",
    "cut_search=jieba.cut_for_search(str_text)\n",
    "lst_search = list(cut_search)\n",
    "print('搜索引擎分词：{ %d}' % len(lst_search))\n",
    "print(\"/\".join(lst_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键词提取、关键词提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "真是好久好久没来哈皮娜拉野生动物园了，记忆里还是小时候三四年级学校组织春游去的银河系。jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。\n",
      "关键词提取:分词/字符串/哈皮/jieba/cut/search/HMM/倒排/细待/unicode/UTF/GBK/春游/粒度/好久好久/方法/记忆里/三四年/搜索引擎/娜拉\n",
      "关键词topk:分词/字符串/哈皮\n",
      "总词数:80\n",
      "从80 中取出8 个词\n",
      "关键词topk分词/字符串/哈皮/jieba/cut/search/HMM/倒排\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "#analyse.extract.tags\n",
    "\n",
    "print(str_text)\n",
    "keywords1=jieba.analyse.extract_tags(str_text)\n",
    "print('关键词提取:'+\"/\".join(keywords1))\n",
    "\n",
    "keywords_top=jieba.analyse.extract_tags(str_text,topK=3)\n",
    "print('关键词topk:'+\"/\".join(keywords_top))     #有时不确定提取多少关键词，可利用总词的百分比\n",
    "print('总词数:{}'.format(len(list(jieba.cut(str_text)))))\n",
    "total=len(list(jieba.cut(str_text)))\n",
    "get_cnt=math.ceil(total*0.1)  #向上取整\n",
    "print('从%d 中取出%d 个词'% (total,get_cnt))\n",
    "keywords_top1=jieba.analyse.extract_tags(str_text,topK=get_cnt)\n",
    "print('关键词topk'+\"/\".join(keywords_top1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加自定义词\n",
    "\n",
    "处理时，add_word(word,freq=None,tag=None)和del_word可在程序中动态修改词典。  \n",
    "suggest_freq(segment,tune=Ture)可调节单词词频，时期能或不能显示  \n",
    "`注：自动计算的词频在使用HMM新词发现功能时可能无效`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_word前:真是/好久好久/没来/哈皮/娜拉/野生动物园/了/，/记忆里/还是/小时候/三四年/级/学校/组织/春游/去/的/银河系/。/jieba/./cut/_/for/_/search/ /方法/接受/两个/参数/：/需要/分词/的/字符串/；/是否/使用/ /HMM/ /模型/。/该/方法/适合/用于/搜索引擎/构建/倒排/索引/的/分词/，/粒度/比较/细待/分词/的/字符串/可以/是/ /unicode/ /或/ /UTF/-/8/ /字符串/、/GBK/ /字符串/。\n",
      "add_word后:真是/好久好久/没来/哈皮/娜拉/野生动物园/了/，/记忆里/还是/小时候/三四年/级/学校/组织/春游/去/的/银河系/。/jieba/./cut/_/for/_/search/ /方法/接受/两个/参数/：/需要/分词/的/字符串/；/是否/使用/ /HMM/ /模型/。/该/方法/适合/用于/搜索引擎/构建/倒排/索引/的/分词/，/粒度/比较/细待/分词/的/字符串/可以/是/ /unicode/ /或/ /UTF/-/8/ /字符串/、/GBK/ /字符串/。\n",
      "suggest_freq后:真是/好久好久/没来/哈皮/娜拉/野生动物园/了/，/记忆里/还是/小时候/三四年/级/学校/组织/春游/去/的/银河系/。/jieba/./cut/_/for/_/search/ /方法/接受/两个/参数/：/需要/分词/的/字符串/；/是否/使用/ /HMM/ /模型/。/该/方法/适合/用于/搜索引擎/构建/倒排/索引/的/分词/，/粒度/比较/细待/分词/的/字符串/可以/是/ /unicode/ /或/ /UTF/-/8/ /字符串/、/GBK/ /字符串/。\n"
     ]
    }
   ],
   "source": [
    "str_jing2=jieba.cut(str_text,cut_all=False)\n",
    "print('add_word前:'+\"/\".join(str_jing2))\n",
    "#添加自定义词\n",
    "jieba.del_word('哈皮娜拉')\n",
    "jieba.del_word('野生')\n",
    "str_jing3=jieba.cut(str_text,cut_all=False)\n",
    "print('add_word后:'+\"/\".join(str_jing3))\n",
    "#修正词频\n",
    "jieba.suggest_freq('野生动物园',tune=True)\n",
    "str_jing4=jieba.cut(str_text,cut_all=False)\n",
    "print('suggest_freq后:'+\"/\".join(str_jing4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载自定义词库\n",
    "\n",
    "jieba.load_userdict(filename)  \n",
    "#filename为文件路径词典格式和dict.txt一样，一词一行，每行分三个部分（用空格隔开），词语 词频（可省） 词性（可省）顺序不可颠倒，若filename为路径或二进制方式打开，则需为UTF-8\n",
    "'''\n",
    "#定义：三四年级  在文件内\n",
    "jieba.load_userdict('C:\\\\Users\\\\lenovo\\\\Desktop\\\\自定义词库.txt')\n",
    "str_load=jieba.cut(str_text,cut_all=False)\n",
    "print('load_userdict后:'+\"/\".join(str_load))\n",
    "'''\n",
    "注jieba.load_userdict加载自定义词库和jieba初始化词库一同使用，但是，默认的初始词库放在安装目录ixia，如果确定长期加载词库，就替换他使用词库的切换功能set_dictionary()\n",
    "可将jieba默认词库copy到自己的目录下，在添加，或者找到更全的词库  \n",
    "'''\n",
    "#一般在python都为site-packages\\jieba\\dict.txt  \n",
    "#模拟演示  \n",
    "jieba.set_dictionary('filename')  \n",
    "#之后进行分词，如果我们切换了词库，此时程序就会初始化我们制定的词库，而不加载默认路径词库  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
